{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhCNoFSK1JAfkuFaICALxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejay34/YaP_Master_OCR/blob/main/python_OpenCV_keras_emnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разбиение текста на буквы"
      ],
      "metadata": {
        "id": "2o36I0fZQLvY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a0N_VClQKDW"
      },
      "outputs": [],
      "source": [
        "image_file = \"text.png\"\n",
        "img = cv2.imread(image_file)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
        "img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
        "\n",
        "# Get contours\n",
        "contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "output = img.copy()\n",
        "\n",
        "for idx, contour in enumerate(contours):\n",
        "    (x, y, w, h) = cv2.boundingRect(contour)\n",
        "    # print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
        "    # hierarchy[i][0]: the index of the next contour of the same level\n",
        "    # hierarchy[i][1]: the index of the previous contour of the same level\n",
        "    # hierarchy[i][2]: the index of the first child\n",
        "    # hierarchy[i][3]: the index of the parent\n",
        "    if hierarchy[0][idx][3] == 0:\n",
        "        cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
        "\n",
        "\n",
        "cv2.imshow(\"Input\", img)\n",
        "cv2.imshow(\"Enlarged\", img_erode)\n",
        "cv2.imshow(\"Output\", output)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## сохраним каждую букву, предварительно отмасштабировав её до квадрата 28х28"
      ],
      "metadata": {
        "id": "QJO-tgYvQX27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def letters_extract(image_file: str, out_size=28) -> List[Any]:\n",
        "    img = cv2.imread(image_file)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
        "    img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
        "\n",
        "    # Get contours\n",
        "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    output = img.copy()\n",
        "\n",
        "    letters = []\n",
        "    for idx, contour in enumerate(contours):\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "        # print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
        "        # hierarchy[i][0]: the index of the next contour of the same level\n",
        "        # hierarchy[i][1]: the index of the previous contour of the same level\n",
        "        # hierarchy[i][2]: the index of the first child\n",
        "        # hierarchy[i][3]: the index of the parent\n",
        "        if hierarchy[0][idx][3] == 0:\n",
        "            cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
        "            letter_crop = gray[y:y + h, x:x + w]\n",
        "            # print(letter_crop.shape)\n",
        "\n",
        "            # Resize letter canvas to square\n",
        "            size_max = max(w, h)\n",
        "            letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
        "            if w > h:\n",
        "                # Enlarge image top-bottom\n",
        "                # ------\n",
        "                # ======\n",
        "                # ------\n",
        "                y_pos = size_max//2 - h//2\n",
        "                letter_square[y_pos:y_pos + h, 0:w] = letter_crop\n",
        "            elif w < h:\n",
        "                # Enlarge image left-right\n",
        "                # --||--\n",
        "                x_pos = size_max//2 - w//2\n",
        "                letter_square[0:h, x_pos:x_pos + w] = letter_crop\n",
        "            else:\n",
        "                letter_square = letter_crop\n",
        "\n",
        "            # Resize letter to 28x28 and add letter and its X-coordinate\n",
        "            letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))\n",
        "\n",
        "    # Sort array in place by X-coordinate\n",
        "    letters.sort(key=lambda x: x[0], reverse=False)\n",
        "\n",
        "    return letters"
      ],
      "metadata": {
        "id": "s3qLXPoyQeBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imshow(\"0\", letters[0][2])\n",
        "cv2.imshow(\"1\", letters[1][2])\n",
        "cv2.imshow(\"2\", letters[2][2])\n",
        "cv2.imshow(\"3\", letters[3][2])\n",
        "cv2.imshow(\"4\", letters[4][2])\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "nSh83sEhQox3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Нейронная сеть (CNN) для распознавания"
      ],
      "metadata": {
        "id": "OO0q3qt5QrZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras import backend as K\n",
        "from keras.constraints import maxnorm\n",
        "import tensorflow as tf\n",
        "\n",
        "def emnist_model():\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(28, 28, 1), activation='relu'))\n",
        "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(emnist_labels), activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "YaoJh67XQsir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение нейронной сети"
      ],
      "metadata": {
        "id": "r_Mn8oVlQxYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import idx2numpy\n",
        "\n",
        "emnist_path = '/home/Documents/TestApps/keras/emnist/'\n",
        "X_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-images-idx3-ubyte')\n",
        "y_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-labels-idx1-ubyte')\n",
        "\n",
        "X_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-images-idx3-ubyte')\n",
        "y_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-labels-idx1-ubyte')\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels))\n",
        "\n",
        "k = 10\n",
        "X_train = X_train[:X_train.shape[0] // k]\n",
        "y_train = y_train[:y_train.shape[0] // k]\n",
        "X_test = X_test[:X_test.shape[0] // k]\n",
        "y_test = y_test[:y_test.shape[0] // k]\n",
        "\n",
        "# Normalize\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_train /= 255.0\n",
        "X_test = X_test.astype(np.float32)\n",
        "X_test /= 255.0\n",
        "\n",
        "x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels))\n",
        "y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))"
      ],
      "metadata": {
        "id": "kl3kSj73Qyb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Запускаем обучение сети, в конце процесса сохраняем обученную модель на диск."
      ],
      "metadata": {
        "id": "bkltf1o3Q5PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a learning rate reduction\n",
        "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "\n",
        "model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30)\n",
        "\n",
        "model.save('emnist_letters.h5')"
      ],
      "metadata": {
        "id": "ezw3rB6EQ6U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Распознавание"
      ],
      "metadata": {
        "id": "BvQWhD_fQ-RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('emnist_letters.h5')\n",
        "\n",
        "def emnist_predict_img(model, img):\n",
        "    img_arr = np.expand_dims(img, axis=0)\n",
        "    img_arr = 1 - img_arr/255.0\n",
        "    img_arr[0] = np.rot90(img_arr[0], 3)\n",
        "    img_arr[0] = np.fliplr(img_arr[0])\n",
        "    img_arr = img_arr.reshape((1, 28, 28, 1))\n",
        "\n",
        "    predict = model.predict([img_arr])\n",
        "    result = np.argmax(predict, axis=1)\n",
        "    return chr(emnist_labels[result[0]])"
      ],
      "metadata": {
        "id": "NMqnEQ4VQ_NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## функция, которая на входе получает файл с изображением, а на выходе дает строку,"
      ],
      "metadata": {
        "id": "dLtqSC_0RFsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_str(model: Any, image_file: str):\n",
        "    letters = letters_extract(image_file)\n",
        "    s_out = \"\"\n",
        "    for i in range(len(letters)):\n",
        "        dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
        "        s_out += emnist_predict_img(model, letters[i][2])\n",
        "        if (dn > letters[i][1]/4):\n",
        "            s_out += ' '\n",
        "    return s_out"
      ],
      "metadata": {
        "id": "eBNAKREfRGk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пример использования:"
      ],
      "metadata": {
        "id": "Y-xPzYhHRMTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('emnist_letters.h5')\n",
        "s_out = img_to_str(model, \"hello_world.png\")\n",
        "print(s_out)"
      ],
      "metadata": {
        "id": "mkevEYgORN4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}